{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tables import *\n",
    "import csv\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/User1/data/self_citations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articles = {}\n",
    "with open(path+'article.txt','r') as f:\n",
    "    reader = csv.reader(f,delimiter='\\t')\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        articles[int(line[0])] = int(line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path+'IDs_network.p','rb') as f:\n",
    "    IDs_network = pickle.load(f)\n",
    "authors_network = {}\n",
    "count = 0\n",
    "with open(path+'author_network.npy','rb') as f:\n",
    "    while True:\n",
    "        try:\n",
    "            authors_network[IDs_network[count]] = np.load(f)\n",
    "            count += 1\n",
    "        except ValueError:\n",
    "            break\n",
    "del IDs_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path+'dict_cite.p','rb') as f:\n",
    "    dict_cite = pickle.load(f)\n",
    "with open(path+'dict_citant.p','rb') as f:\n",
    "    dict_citant = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path+'dict_cluster_art.p','rb') as f:\n",
    "    dict_cluster_art = pickle.load(f)\n",
    "with open(path+'dict_cluster_ID.p','rb') as f:\n",
    "    dict_cluster_ID = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path+'authors_disc.p','rb') as f:\n",
    "    authors_disc_idx = pickle.load(f)\n",
    "list_disciplines = list(authors_disc_idx.keys())\n",
    "nb_disciplines = len(list_disciplines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_year = 1980\n",
    "max_year = 2019\n",
    "nb_years = max_year-min_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "authors_info = {}\n",
    "with open(path+'authors_info.csv','r') as f:\n",
    "    reader = csv.reader(f,delimiter='\\t')\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        authors_info[int(line[0])] = [line[1],int(line[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/User1/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685e178c4e9c4e78a7d9e63ebdd67d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "citants = list(dict_citant.keys())\n",
    "nb_citants = len(citants)\n",
    "idx = np.arange(nb_citants)\n",
    "citant_per_year = np.zeros(nb_years)\n",
    "ref_per_year = np.zeros(nb_years)\n",
    "for i in tqdm(range(nb_citants)):\n",
    "    art_citant = citants[idx[i]]\n",
    "    year_citant = articles[art_citant]\n",
    "    if year_citant >= min_year and year_citant < max_year:\n",
    "        rel_year_citant = year_citant - min_year\n",
    "        citant_per_year[rel_year_citant] += 1\n",
    "        ref_per_year[rel_year_citant] += len(dict_citant[art_citant])\n",
    "cit_per_art_year = np.divide(ref_per_year,citant_per_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_citant = 1/(cit_per_art_year/max(cit_per_art_year))\n",
    "weight_citant = {year:weight_citant[i] for i,year in enumerate(range(min_year,max_year))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "authors = list(dict_cluster_ID.keys())\n",
    "nb_authors = len(authors)\n",
    "idx = np.arange(nb_authors)\n",
    "np.random.shuffle(idx)\n",
    "total_iterations = nb_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(path+'progress.txt','w')\n",
    "count = 0\n",
    "citations = {d:sparse.lil_matrix((len(authors_disc_idx[d]),nb_years)) for d in list_disciplines}\n",
    "start_time = time.time()\n",
    "for i in range(nb_authors):\n",
    "    count += 1\n",
    "    author_ID = authors[idx[i]]\n",
    "    arts_author = dict_cluster_ID[author_ID]\n",
    "    if author_ID in authors_network:\n",
    "        network = authors_network[author_ID]\n",
    "        years_net = np.unique(network[1,:])\n",
    "        dict_network = {}\n",
    "        for year in years_net:\n",
    "            dict_network[year] = set(network[0,np.where(network[1,:]<=year)[0]])\n",
    "\n",
    "        for art_cite in arts_author:\n",
    "            year_cite = articles[art_cite]\n",
    "            if year_cite >= min_year and year_cite < max_year:\n",
    "                if art_cite in dict_cite:\n",
    "                    authors_cite = set(dict_cluster_art[art_cite])\n",
    "                    arts_citant = dict_cite[art_cite]\n",
    "                    for art_citant in arts_citant:\n",
    "                        year_citant = articles[art_citant]\n",
    "                        if year_citant >= min_year and year_citant < max_year:\n",
    "                            weight = weight_citant[year_citant]\n",
    "                            if art_citant in dict_cluster_art:\n",
    "                                authors_citant = set(dict_cluster_art[art_citant])\n",
    "                                int_authors = authors_cite.intersection(authors_citant)\n",
    "                                if len(int_authors) == 0:\n",
    "                                    id_years = years_net[np.where(years_net<=year_citant)[0]]\n",
    "                                    if len(id_years) > 0:\n",
    "                                        year_network = np.max(id_years)\n",
    "                                        network = dict_network[year_network]\n",
    "                                        if len(authors_citant.intersection(network)) > 0:\n",
    "                                            info = authors_info[author_ID]\n",
    "                                            author_age = year_citant - info[1]\n",
    "                                            if author_age < nb_years:\n",
    "                                                disc = info[0]\n",
    "                                                author_idx = authors_disc_idx[disc][author_ID]\n",
    "                                                citations[disc][author_idx,author_age] += weight\n",
    "\n",
    "    if count % 1000 == 1 :\n",
    "        elapsed_time = time.time() - start_time\n",
    "        elapsed_time_h = np.round(elapsed_time/3600,2)\n",
    "        time_per_art = elapsed_time/count\n",
    "        time_left_h = np.round(time_per_art*(total_iterations-count)/3600,2)\n",
    "        perc = np.round(count/total_iterations*100,3)\n",
    "        f.write('Progress: {} articles, {}%, Time since start: {}, Time left: {}\\n'.format(count,perc,elapsed_time_h,time_left_h))    \n",
    "        f.flush()\n",
    "\n",
    "\n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for disc in list_disciplines:\n",
    "    with open('{}/arrays/citations_{}_{}_network_array_norm.npz'.format(path,'self',disc),'wb') as f2:\n",
    "        sparse.save_npz(f2,sparse.csr_matrix(citations[disc]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(path+'progress.txt','w')\n",
    "count = 0\n",
    "references = {d:sparse.lil_matrix((len(authors_disc_idx[d]),nb_years)) for d in list_disciplines}\n",
    "start_time = time.time()\n",
    "for i in range(nb_authors):\n",
    "    count += 1\n",
    "    author_ID = authors[idx[i]]\n",
    "    arts_author = dict_cluster_ID[author_ID]\n",
    "    if author_ID in authors_network:\n",
    "        network = authors_network[author_ID]\n",
    "        years_net = np.unique(network[1,:])\n",
    "        dict_network = {}\n",
    "        for year in years_net:\n",
    "            dict_network[year] = set(network[0,np.where(network[1,:]<=year)[0]])\n",
    "\n",
    "        for art_citant in arts_author:\n",
    "            year_citant = articles[art_citant]\n",
    "            if year_citant >= min_year and year_citant < max_year:\n",
    "                weight = weight_citant[year_citant]\n",
    "                if art_citant in dict_citant:\n",
    "                    arts_cite = dict_citant[art_citant]\n",
    "                    authors_citant = set(dict_cluster_art[art_citant])\n",
    "                    for art_cite in arts_cite:\n",
    "                        if art_cite in dict_cluster_art:\n",
    "                            authors_cite = set(dict_cluster_art[art_cite])\n",
    "                            int_authors = authors_cite.intersection(authors_citant)\n",
    "                            if len(int_authors) == 0:\n",
    "                                id_years = years_net[np.where(years_net<=year_citant)[0]]\n",
    "                                if len(id_years) > 0:\n",
    "                                    year_network = np.max(id_years)\n",
    "                                    network = dict_network[year_network]\n",
    "                                    if len(authors_cite.intersection(network)) > 0:\n",
    "                                        info = authors_info[author_ID]\n",
    "                                        author_age = year_citant - info[1]\n",
    "                                        if author_age < nb_years:\n",
    "                                            disc = info[0]\n",
    "                                            author_idx = authors_disc_idx[disc][author_ID]\n",
    "                                            references[disc][author_idx,author_age] += weight\n",
    "\n",
    "    if count % 1000 == 1 :\n",
    "        elapsed_time = time.time() - start_time\n",
    "        elapsed_time_h = np.round(elapsed_time/3600,2)\n",
    "        time_per_art = elapsed_time/count\n",
    "        time_left_h = np.round(time_per_art*(total_iterations-count)/3600,2)\n",
    "        perc = np.round(count/total_iterations*100,3)\n",
    "        f.write('Progress: {} articles, {}%, Time since start: {}, Time left: {}\\n'.format(count,perc,elapsed_time_h,time_left_h))    \n",
    "        f.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for disc in list_disciplines:\n",
    "    with open('{}/arrays/references_{}_{}_network_array_norm.npz'.format(path,'self',disc),'wb') as f2:\n",
    "        sparse.save_npz(f2,sparse.csr_matrix(references[disc]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find average coaut years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/User1/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d84aa0529e476cad9273cce4bae4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "citants = list(dict_citant.keys())\n",
    "nb_citants = len(citants)\n",
    "idx = np.arange(nb_citants)\n",
    "citant_per_year = np.zeros(nb_years)\n",
    "aut_per_year = np.zeros(nb_years)\n",
    "for i in tqdm(range(nb_citants)):\n",
    "    art_citant = citants[idx[i]]\n",
    "    year_citant = articles[art_citant]\n",
    "    if year_citant >= min_year and year_citant < max_year:\n",
    "        rel_year_citant = year_citant - min_year\n",
    "        if art_citant in dict_cluster_art:\n",
    "            citant_per_year[rel_year_citant] += 1\n",
    "            aut_per_year[rel_year_citant] += len(dict_cluster_art[art_citant])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aut_per_art_year = np.divide(aut_per_year,citant_per_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.58639224, 2.63546928, 2.6720403 , 2.7174379 , 2.76292371,\n",
       "       2.81186071, 2.87538792, 2.939422  , 3.00449287, 3.06479835,\n",
       "       3.13572934, 3.16195584, 3.30481557, 3.39004444, 3.44409977,\n",
       "       3.54330382, 3.58947494, 3.66406739, 3.69684414, 3.74507228,\n",
       "       3.80855104, 3.86737572, 3.91751835, 3.98328911, 4.11292973,\n",
       "       4.18540465, 4.23553708, 4.29401113, 4.32872316, 4.39928687,\n",
       "       4.56883694, 4.81484474, 5.09681504, 5.08702321, 5.15607434,\n",
       "       5.30105618, 5.44910048, 5.52269407, 5.60170041])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aut_per_art_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/User1/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7f9aa365b4493db4208a29ea84ca74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "citant_per_year = np.zeros(nb_years)\n",
    "has_clus_per_year = np.zeros(nb_years)\n",
    "for i in tqdm(range(nb_citants)):\n",
    "    art_citant = citants[idx[i]]\n",
    "    year_citant = articles[art_citant]\n",
    "    if year_citant >= min_year and year_citant < max_year:\n",
    "        rel_year_citant = year_citant - min_year\n",
    "        citant_per_year[rel_year_citant] += 1\n",
    "        if art_citant in dict_cluster_art:\n",
    "            has_clus_per_year[rel_year_citant] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99710706, 0.9975832 , 0.9980145 , 0.99787865, 0.99814447,\n",
       "       0.99774353, 0.99812773, 0.99670111, 0.99830335, 0.99846729,\n",
       "       0.99850549, 0.99803272, 0.99790516, 0.99891002, 0.99899947,\n",
       "       0.99912394, 0.99900148, 0.9988984 , 0.99858032, 0.99857196,\n",
       "       0.99821485, 0.99791223, 0.99862986, 0.99846309, 0.99801614,\n",
       "       0.99825666, 0.99648094, 0.9291154 , 0.99687118, 0.932903  ,\n",
       "       0.99343935, 0.99339224, 0.97513723, 0.99734763, 0.95275385,\n",
       "       0.99451635, 0.86741259, 0.98746563, 0.16694203])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_clus_year = np.divide(has_clus_per_year,citant_per_year)\n",
    "perc_clus_year "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
