{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the 100 gb ram instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tables import *\n",
    "import csv\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/User1/data/self_citations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path+'ordered_arts.p','rb') as f:\n",
    "    ordered_arts= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path+'dict_citant.p','rb') as f:\n",
    "    dict_citant = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path+'dict_cluster_art.p','rb') as f:\n",
    "    dict_cluster_art = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articles = {}\n",
    "with open(path+'article.txt','r') as f:\n",
    "    reader = csv.reader(f,delimiter='\\t')\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        articles[int(line[0])] = int(line[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Run on first time only \n",
    "authors_info = pd.read_csv(path+'authors_info.csv',sep='\\t')\n",
    "nb_authors_disc = authors_info.groupby('EDiscipline').agg('count')\n",
    "list_disciplines = nb_authors_disc.index\n",
    "authors_disc_idx = {}\n",
    "for disc in list_disciplines:\n",
    "    #Cluster_ID:pos\n",
    "    authors_disc_idx[disc] = {x[1]['Cluster_ID']:i for i,x in enumerate(authors_info.loc[authors_info['EDiscipline'] == disc].iterrows())}\n",
    "with open(path+'authors_disc.p','wb') as f:\n",
    "    pickle.dump(authors_disc_idx,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path+'authors_disc.p','rb') as f:\n",
    "    authors_disc_idx = pickle.load(f)\n",
    "list_disciplines = list(authors_disc_idx.keys())\n",
    "nb_disciplines = len(list_disciplines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_year = 1980\n",
    "max_year = 2019\n",
    "nb_years = max_year-min_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citants = list(dict_citant.keys())\n",
    "nb_citants = len(citants)\n",
    "idx = np.arange(nb_citants)\n",
    "np.random.shuffle(idx)\n",
    "total_iterations = nb_citants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,   11,\n",
       "         12,   13,   14,   15,   16,   17,   18,   19,   20,   21,   22,\n",
       "         23,   24,   25,   26,   27,   28,   29,   30,   31,   32,   33,\n",
       "         34,   35,   36,   37,   38,   39,   40,   41,   42,   43,   44,\n",
       "         45,   46,   47,   48,   49,   50,   60,   70,   80,   90,  100,\n",
       "        110,  120,  130,  140,  150,  160,  170,  180,  190,  200,  300,\n",
       "        400,  500,  600,  700,  800,  900, 1000])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins_nb_arts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins_nb_arts = np.concatenate([np.arange(1,50),np.arange(50,200,10),np.arange(200,1100,100),np.array([1500,2000])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_bins = len(bins_nb_arts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_bin = np.min(bins_nb_arts)\n",
    "max_bin = np.max(bins_nb_arts)\n",
    "bins_map = {}\n",
    "for i in range(min_bin,max_bin+1):\n",
    "    bins_map[i] = np.argmax(np.where(bins_nb_arts<=i)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute year normalized citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/User1/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066d95c0c9d04347b3ec3296c0d7cc84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "citant_per_year = np.zeros(nb_years)\n",
    "ref_per_year = np.zeros(nb_years)\n",
    "for i in tqdm(range(nb_citants)):\n",
    "    art_citant = citants[idx[i]]\n",
    "    year_citant = articles[art_citant]\n",
    "    if year_citant >= min_year and year_citant < max_year:\n",
    "        rel_year_citant = year_citant - min_year\n",
    "        citant_per_year[rel_year_citant] += 1\n",
    "        ref_per_year[rel_year_citant] += len(dict_citant[art_citant])\n",
    "cit_per_art_year = np.divide(ref_per_year,citant_per_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_citant = 1/(cit_per_art_year/max(cit_per_art_year))\n",
    "weight_citant = {year:weight_citant[i] for i,year in enumerate(range(min_year,max_year))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(path+'progress.txt','w')\n",
    "type_cit = 'self'\n",
    "freq_bins = {d:sparse.lil_matrix((len(authors_disc_idx[d]),nb_bins)) for d in list_disciplines}\n",
    "citations = {d:sparse.lil_matrix((len(authors_disc_idx[d]),nb_bins)) for d in list_disciplines}\n",
    "start_time = time.time()\n",
    "count = 0\n",
    "for i in range(nb_citants):\n",
    "    count += 1\n",
    "    art_citant = citants[idx[i]]\n",
    "    year_citant = articles[art_citant]\n",
    "    if year_citant >= min_year and year_citant < max_year:\n",
    "        weight = weight_citant[year_citant]\n",
    "        if art_citant in dict_cluster_art:\n",
    "            authors_citant = set(dict_cluster_art[art_citant])\n",
    "            refs_citant = set(dict_citant[art_citant])\n",
    "            for ref in refs_citant:\n",
    "                if ref in dict_cluster_art:\n",
    "                    authors_cite = set(dict_cluster_art[ref])\n",
    "                    int_authors = authors_cite.intersection(authors_citant)\n",
    "                    if len(int_authors) == 0:\n",
    "                        for ID_author in int_authors:\n",
    "                            info = authors_info[ID_author]\n",
    "                            author_age = year_citant - info[1]\n",
    "                            arts_author_cite = ordered_arts[ID_author_cite]\n",
    "                            pos = np.where(ordered_arts[ID_author_cite])\n",
    "                            if author_age < nb_years:\n",
    "                                if pos in bins_map:\n",
    "                                    pos_bin = bins_map[pos]\n",
    "                                    disc = info[0]\n",
    "                                    author_idx = authors_disc_idx[disc][ID_author]\n",
    "                                    citations[disc][author_idx,pos_bin] += weight\n",
    "                                    freq_bins[disc][author_idx,pos_bin] += weight\n",
    "                    \n",
    "    if count % 1000 == 1 :\n",
    "        elapsed_time = time.time() - start_time\n",
    "        elapsed_time_h = np.round(elapsed_time/3600,2)\n",
    "        time_per_art = elapsed_time/count\n",
    "        time_left_h = np.round(time_per_art*(total_iterations-count)/3600,2)\n",
    "        perc = np.round(count/total_iterations*100,3)\n",
    "        f.write('Progress: {} articles, {}%, Time since start: {}, Time left: {}\\n'.format(count,perc,elapsed_time_h,time_left_h))    \n",
    "        f.flush()\n",
    "for disc in list_disciplines:\n",
    "    with open('{}/arrays/citations_{}_{}_array_norm_artPos.npz'.format(path,type_cit,disc),'wb') as f2:\n",
    "        sparse.save_npz(f2,sparse.csr_matrix(citations[disc]))\n",
    "    with open('{}/arrays/freq_bins_{}_{}_array_norm_artPos.npz'.format(path,type_cit,disc),'wb') as f2:\n",
    "        sparse.save_npz(f2,sparse.csr_matrix(freq_bins[disc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(path+'progress.txt','w')\n",
    "type_cit = 'self'\n",
    "references = {d:sparse.lil_matrix((len(authors_disc_idx[d]),nb_bins)) for d in list_disciplines}\n",
    "citations = {d:sparse.lil_matrix((len(authors_disc_idx[d]),nb_bins)) for d in list_disciplines}\n",
    "start_time = time.time()\n",
    "count = 0\n",
    "for i in range(nb_citants):\n",
    "    count += 1\n",
    "    art_citant = citants[idx[i]]\n",
    "    year_citant = articles[art_citant]\n",
    "    if year_citant >= min_year and year_citant < max_year:\n",
    "        weight = weight_citant[year_citant]\n",
    "        if art_citant in dict_cluster_art:\n",
    "            authors_citant = set(dict_cluster_art[art_citant])\n",
    "            refs_citant = set(dict_citant[art_citant])\n",
    "            for ref in refs_citant:\n",
    "                if ref in dict_cluster_art:\n",
    "                    authors_cite = set(dict_cluster_art[ref])\n",
    "                    int_authors = authors_cite.intersection(authors_citant)\n",
    "                    if len(int_authors) == 0:\n",
    "                        for ID_author in int_authors:\n",
    "                            info = authors_info[ID_author]\n",
    "                            author_age = year_citant - info[1]\n",
    "                            arts_author_cite = ordered_arts[ID_author_cite]\n",
    "                            pos = np.where(ordered_arts[ID_author_cite])\n",
    "                            if author_age < nb_years:\n",
    "                                if pos in bins_map:\n",
    "                                    pos_bin = bins_map[pos]\n",
    "                                    disc = info[0]\n",
    "                                    author_idx = authors_disc_idx[disc][ID_author]\n",
    "                                    citations[disc][author_idx,pos_bin] += weight\n",
    "                                    references[disc][author_idx,pos_bin] += weight\n",
    "                    \n",
    "    if count % 1000 == 1 :\n",
    "        elapsed_time = time.time() - start_time\n",
    "        elapsed_time_h = np.round(elapsed_time/3600,2)\n",
    "        time_per_art = elapsed_time/count\n",
    "        time_left_h = np.round(time_per_art*(total_iterations-count)/3600,2)\n",
    "        perc = np.round(count/total_iterations*100,3)\n",
    "        f.write('Progress: {} articles, {}%, Time since start: {}, Time left: {}\\n'.format(count,perc,elapsed_time_h,time_left_h))    \n",
    "        f.flush()\n",
    "for disc in list_disciplines:\n",
    "    with open('{}/arrays/citations_{}_{}_array_norm_artPos.npz'.format(path,type_cit,disc),'wb') as f2:\n",
    "        sparse.save_npz(f2,sparse.csr_matrix(citations[disc]))\n",
    "    with open('{}/arrays/references_{}_{}_array_norm_artPos.npz'.format(path,type_cit,disc),'wb') as f2:\n",
    "        sparse.save_npz(f2,sparse.csr_matrix(references[disc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for disc in list_disciplines:\n",
    "    with open('{}/arrays/citations_{}_{}_array_norm.npz'.format(path,type_cit,disc),'wb') as f2:\n",
    "        sparse.save_npz(f2,sparse.csr_matrix(citations[disc]))\n",
    "    with open('{}/arrays/references_{}_{}_array_norm.npz'.format(path,type_cit,disc),'wb') as f2:\n",
    "        sparse.save_npz(f2,sparse.csr_matrix(references[disc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#references = {d:{z:{y:sparse.lil_matrix((len(authors_disc_idx[d]),nb_years)) for y in ['self','co','others']} for z in ['age','year']} for d in list_disciplines}\n",
    "#citations = {d:{z:{y:sparse.lil_matrix((len(authors_disc_idx[d]),nb_years)) for y in ['self','co','others']} for z in ['age','year']} for d in list_disciplines}\n",
    "references = {d:{y:sparse.lil_matrix((len(authors_disc_idx[d]),nb_years)) for y in ['self','co','others']} for d in list_disciplines}\n",
    "citations = {d:{y:sparse.lil_matrix((len(authors_disc_idx[d]),nb_years)) for y in ['self','co','others']} for d in list_disciplines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%lprun -f prof_lines prof_lines()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
